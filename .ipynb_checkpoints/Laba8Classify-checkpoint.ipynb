{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing base libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and importing everything we need in this lab\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading ARFF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "ARFF_FILE = 'diabetes.arff' # file is in the same folder, as jupyter is ran, and ipynb file\n",
    "\n",
    "arff_data = arff.loadarff(ARFF_FILE)\n",
    "df = pd.DataFrame(arff_data[0])\n",
    "df.head(5) # first 5 entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['class']\n",
    "data = df.drop(columns=['class'])\n",
    "target = target.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import dummy, metrics\n",
    "\n",
    "baseline = dummy.DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(data, target)\n",
    "base_predictions = baseline.predict(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    pyplot.imshow(matrix, interpolation='nearest', cmap=cmap)\n",
    "    pyplot.title(title)\n",
    "    pyplot.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    pyplot.xticks(tick_marks, classes, rotation=45)\n",
    "    pyplot.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, format(matrix[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.ylabel('True label')\n",
    "    pyplot.xlabel('Predicted label')\n",
    "    pyplot.show()\n",
    "    pyplot.clf()\n",
    "    pyplot.cla()\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = dummy.DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(data, target)\n",
    "base_predictions = baseline.predict(data)\n",
    "\n",
    "accuracy = metrics.accuracy_score(target, base_predictions)\n",
    "print (\"Accuracy = {:.3f}\".format(accuracy))\n",
    "\n",
    "print(metrics.classification_report(target, base_predictions))\n",
    "\n",
    "plot_confusion_matrix(metrics.confusion_matrix(target, base_predictions), \n",
    "                      classes=target.unique(), \n",
    "                      title='Diabetes most frequent baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(data, target, test_size=0.33)\n",
    "print(\"Training data size: {}\".format(len(train_data)))\n",
    "print(\"Testing data size: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "diabetes_split_tree_model = tree.DecisionTreeClassifier(presort=True,       # shows better results\n",
    "                                                        max_features='auto',\n",
    "                                                        min_samples_leaf=5, # prevent overlearning\n",
    "                                                        random_state=0)     # make sure random is controlled\n",
    "diabetes_split_tree_model.fit(train_data, train_labels)\n",
    "print('Model fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz # needs isntalling graphviz\n",
    "\n",
    "def print_tree(_tree):\n",
    "    print(\"Depth: {}\".format(_tree.tree_.max_depth))\n",
    "    dot_data = tree.export_graphviz(_tree, out_file=None)\n",
    "    graph = graphviz.Source(dot_data) \n",
    "    return graph\n",
    "\n",
    "print_tree(diabetes_split_tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(labels, predictions, title='Diabetes testing train split tree'):\n",
    "    \"Prints the matrix and accuracy of predictions\"\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "\n",
    "    print (\"Accuracy = {:.3f}\".format(accuracy))\n",
    "\n",
    "    print(metrics.classification_report(labels, predictions))\n",
    "\n",
    "    plot_confusion_matrix(metrics.confusion_matrix(labels, predictions), \n",
    "                          classes=labels.unique(), \n",
    "                          title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tree_predictions = diabetes_split_tree_model.predict(test_data)\n",
    "\n",
    "print_classification_report(test_labels,  split_tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes_cv_tree_model = tree.DecisionTreeClassifier(random_state=1, \n",
    "                                                     min_samples_leaf=2)\n",
    "\n",
    "folds = 5\n",
    "\n",
    "acc_scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "recall_scorer = metrics.make_scorer(metrics.recall_score, average='weighted')\n",
    "prec_scorer = metrics.make_scorer(metrics.precision_score, average='weighted')\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, average='weighted')\n",
    "\n",
    "scoring = {'accuracy': acc_scorer, \n",
    " 'recall': recall_scorer, \n",
    " 'precision' : prec_scorer,\n",
    " 'f1': f1_scorer}\n",
    "\n",
    "# More information:\n",
    "# https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\n",
    "\n",
    "cv_tree_model_scores = ms.cross_validate(diabetes_cv_tree_model,\n",
    "                                         data,\n",
    "                                         target,\n",
    "                                         scoring=scoring,\n",
    "                                         cv=folds,\n",
    "                                         return_train_score=True)\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Evaluation results for {} folds'.format(folds))\n",
    "\n",
    "for (k,v) in cv_tree_model_scores.items():\n",
    " print(('{}: {}').format(k,v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validtion predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diabetes_cv_predict_tree_model = tree.DecisionTreeClassifier(presort=True,       # shows better results\n",
    "                                                             max_features='auto',\n",
    "                                                             min_samples_leaf=5, # prevent overlearning\n",
    "                                                             random_state=0)\n",
    "\n",
    "cv_tree_predictions = ms.cross_val_predict(diabetes_cv_predict_tree_model, \n",
    "                                           data, \n",
    "                                           target,\n",
    "                                           cv=folds)\n",
    "\n",
    "print_classification_report(target,  cv_tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing \n",
    "```\n",
    "Do-it-all-at-once function for SOLID purpose\n",
    "Common definition for all classifiers\n",
    "Common dict for test and train data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do-it-all-at-once function for SOLID purpose\n",
    "def CV_report(classifier, hyperparameters, data_params):\n",
    "    \n",
    "    # Parsing class name of a classifier\n",
    "    module, class_name = classifier.rsplit('.', 1)\n",
    "    __import__(module) # importing is important so module is visible in sys.modules\n",
    "    classifier_class = getattr(sys.modules[module], class_name)\n",
    "    \n",
    "    # Parsing data\n",
    "    train_data = data_params['train']['data']\n",
    "    train_labels = data_params['train']['labels']\n",
    "    test_data = data_params['test']['data']\n",
    "    test_labels = data_params['test']['labels']\n",
    "    \n",
    "    # Creating and griding classifier\n",
    "    classifier = classifier_class()\n",
    "    grid = ms.GridSearchCV(\n",
    "        classifier,\n",
    "        hyperparameters,\n",
    "        refit=True,\n",
    "        scoring=f1_scorer,\n",
    "        iid=True,\n",
    "        cv=6 # TODO: change or pass\n",
    "    )\n",
    "    \n",
    "    # Fitting\n",
    "    model = grid.fit(train_data, train_labels)\n",
    "    print(\"Best parameters:\")\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    \n",
    "    # Predicting\n",
    "    predictions = grid.predict(test_data)\n",
    "        \n",
    "    # Plotting\n",
    "    print_classification_report(test_labels, predictions, title=classifier_class.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common definitio for all classifiers\n",
    "# Looks like: (module, Classifier) : [{hyper parameters}]\n",
    "#import sklearn.tree\n",
    "#import sklearn.svm\n",
    "#import sklearn.linear_model\n",
    "\n",
    "CLASSIFIERS = {\n",
    "    # DecisionTree\n",
    "    'sklearn.tree.DecisionTreeClassifier': [{\n",
    "        'presort':[True, False],       \n",
    "        'max_features':['auto', 1, 2, 3],\n",
    "        'min_samples_leaf':[2, 3, 4, 5, 6],\n",
    "        'random_state':[0, None]\n",
    "    }],\n",
    "    # SVC\n",
    "    'sklearn.svm.SVC': [\n",
    "        {\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': [1e-3],\n",
    "            'C': [1, 10],\n",
    "        },\n",
    "        {\n",
    "            'kernel': ['linear'], \n",
    "            'gamma': [1e-4],\n",
    "            'C': [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    # LogisticRegression\n",
    "    'sklearn.linear_model.LogisticRegressionCV': [{\n",
    "        'max_iter':[1000],\n",
    "        'penalty':['l1'],\n",
    "        'solver':['saga', 'liblinear'], # only acceptable for for l1\n",
    "        'scoring':['roc_auc'],\n",
    "    }, {\n",
    "        'scoring':['roc_auc'],\n",
    "        'penalty':['l2'],\n",
    "        'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    }],\n",
    "    'sklearn.naive_bayes.GaussianNB': [{\n",
    "        'var_smoothing': [1e-3, 1e-7, 1e-9],\n",
    "    }],\n",
    "    'sklearn.ensemble.RandomForestClassifier': [{\n",
    "        'n_estimators':[50, 100, 120],\n",
    "        'criterion':['entropy', 'gini'],\n",
    "        'max_depth':[None, 8, 13],\n",
    "        'min_samples_split':[1,3],\n",
    "        'min_samples_leaf':[1,3],\n",
    "        'max_features':['auto', 'log2', 'sqrt'],\n",
    "        'bootstrap':[True, False],\n",
    "    }],\n",
    "    'sklearn.ensemble.AdaBoostClassifier': [{\n",
    "        \n",
    "    }]\n",
    "}\n",
    "\n",
    "# Common dict for test and train data\n",
    "DATA = {\n",
    "    'train': {\n",
    "        'data': train_data,\n",
    "        'labels': train_labels,\n",
    "    },\n",
    "    'test': {\n",
    "        'data': test_data,\n",
    "        'labels': test_labels,\n",
    "    },\n",
    "    'all': {\n",
    "        'data': data,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying and cross validating\n",
    "#### Going to take a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for (classifier, hyperparams) in CLASSIFIERS.items():\n",
    "    print('*' * 70)\n",
    "    print(\"Using {}...\".format(classifier_class_str))\n",
    "    # Each classificator gets initialized and passed to CV Grid\n",
    "    # Then a common report is created and matrix is vizualized    \n",
    "    CV_report(classifier, \n",
    "              hyperparams, \n",
    "              DATA)\n",
    "    print('*' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing any classifier\n",
    "classifier = 'sklearn.ensemble.RandomForestClassifier'\n",
    "__import__(classifier.rsplit('.', 1)[0])\n",
    "class_ = getattr(sys.modules[classifier.rsplit('.',1)[0]], classifier[1])\n",
    "CV_report(class_, CLASSIFIERS[classifier], DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
